"""
ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Phase 3 ë²„ì „)

Phase 2 ê¸°ëŠ¥:
- LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ (InsightAgent)
- ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (ActionPlanningAgent)
- ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (ReportAgent)

Phase 3 ì¶”ê°€ ê¸°ëŠ¥:
- ì‹œê°í™” ì„œë¹„ìŠ¤ (VisualizationService)
"""
import time
from typing import Dict, Any, Optional
from pathlib import Path
import yaml

from data.loaders.json_loader import JSONReviewLoader
from data.preprocessor import DataPreprocessor
from agents.data_collection_agent import DataCollectionAgent
from agents.sentiment_agent import SentimentAnalysisAgent
from agents.insight_agent import InsightExtractionAgent
from agents.action_planning_agent import ActionPlanningAgent
from agents.report_agent import ReportGenerationAgent
from services.llm_service import create_llm_service
from services.visualization_service import VisualizationService
from utils.logger import get_logger
from core.exceptions import ReviewAnalysisException


class ReviewAnalysisOrchestrator:
    """ë¦¬ë·° ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Phase 3)"""

    VERSION = "3.0.0"

    def __init__(self, config: Dict[str, Any], llm_config_path: Optional[str] = None):
        """
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            llm_config_path: LLM ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒ, ê¸°ë³¸: config/llm_config.yaml)
        """
        self.config = config
        self.logger = get_logger(
            "Orchestrator",
            level=config.get('log_level', 'INFO')
        )

        # LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        if llm_config_path is None:
            llm_config_path = Path(__file__).parent.parent / "config" / "llm_config.yaml"

        self.llm_service = self._init_llm_service(llm_config_path)

        # Phase 1 ì—ì´ì „íŠ¸
        self.data_agent = DataCollectionAgent(config)
        self.sentiment_agent = SentimentAnalysisAgent(config)

        # Phase 2 ì—ì´ì „íŠ¸ (LLM ê¸°ë°˜)
        self.insight_agent = InsightExtractionAgent(config, self.llm_service)
        self.action_planning_agent = ActionPlanningAgent(config, self.llm_service)
        self.report_agent = ReportGenerationAgent(config, self.llm_service)

        # Phase 3 ì„œë¹„ìŠ¤
        self.visualization_service = VisualizationService(logger=self.logger)

        # ë°ì´í„° ì „ì²˜ë¦¬ê¸°
        self.preprocessor = DataPreprocessor()

        self.results: Dict[str, Any] = {}

    def _init_llm_service(self, config_path: Path):
        """LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                llm_config = yaml.safe_load(f)

            service = create_llm_service(llm_config)
            self.logger.info(f"LLM service initialized: {llm_config.get('provider', 'unknown')}")
            return service

        except Exception as e:
            self.logger.warning(f"Failed to initialize LLM service: {e}")
            self.logger.warning("LLM-based features will be disabled")
            return None

    def run_analysis(
        self,
        data_path: str,
        product_id: Optional[str] = None,
        limit: Optional[int] = None,
        enable_llm: bool = True
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Phase 2)

        Args:
            data_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            product_id: ì œí’ˆ ID (ì„ íƒ)
            limit: ë¡œë“œí•  ë¦¬ë·° ìˆ˜ ì œí•œ (ì„ íƒ)
            enable_llm: LLM ê¸°ë°˜ ë¶„ì„ í™œì„±í™” (ê¸°ë³¸: True)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ Review Analysis System Started (Phase 2)")
        self.logger.info("=" * 60)

        start_time = time.time()

        try:
            # Stage 1: ë°ì´í„° ë¡œë“œ
            self.logger.info("\nğŸ“¥ Stage 1: Data Loading...")
            df = self._load_data(data_path, product_id, limit)

            # Stage 2: ë°ì´í„° ì „ì²˜ë¦¬
            self.logger.info("\nğŸ”§ Stage 2: Data Preprocessing...")
            df = self._preprocess_data(df)

            # Stage 3: ë°ì´í„° ìˆ˜ì§‘ ë° ê¸°ë³¸ í†µê³„
            self.logger.info("\nğŸ“Š Stage 3: Data Collection & Statistics...")
            collection_result = self._collect_data(df)

            # Stage 4: ê°ì„± ë¶„ì„
            self.logger.info("\nğŸ’­ Stage 4: Sentiment Analysis...")
            sentiment_result = self._analyze_sentiment(collection_result)

            # ê²°ê³¼ í†µí•© (Phase 1)
            self.results = {
                "basic_stats": collection_result['stats'],
                "sentiment_analysis": sentiment_result,
                "negative_reviews_count": len(collection_result['negative_reviews']),
                "recent_reviews_count": len(collection_result['recent_reviews']),
                "metadata": {
                    "product_id": product_id,
                    "total_reviews_analyzed": collection_result['stats']['total_reviews'],
                    "version": self.VERSION,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                }
            }

            # Phase 2: LLM ê¸°ë°˜ ë¶„ì„ (ì„ íƒì )
            if enable_llm and self.llm_service is not None:
                # Stage 5: ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
                self.logger.info("\nğŸ” Stage 5: Insight Extraction (LLM)...")
                insight_result = self._extract_insights(collection_result)
                self.results["insights"] = insight_result

                # Stage 6: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
                self.logger.info("\nğŸ“‹ Stage 6: Action Planning (LLM)...")
                action_result = self._plan_actions(
                    insight_result.get("pain_points", []),
                    collection_result['stats']
                )
                self.results["action_plan"] = action_result

                # Stage 7: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
                self.logger.info("\nğŸ“„ Stage 7: Report Generation (LLM)...")
                report_result = self._generate_report(
                    product_id,
                    collection_result['stats'],
                    insight_result.get("insights", {}),
                    action_result.get("action_plan", {})
                )
                self.results["final_report"] = report_result

                self.logger.info("\nâœ… LLM-based analysis completed")
            else:
                if not enable_llm:
                    self.logger.info("\nâ© LLM analysis skipped (enable_llm=False)")
                else:
                    self.logger.warning("\nâš ï¸  LLM service not available, skipping Phase 2")

            # Phase 3: Stage 8 - ì‹œê°í™”
            self.logger.info("\nğŸ“Š Stage 8: Visualization (Phase 3)...")
            charts = self._generate_visualizations(df, sentiment_result)
            if charts:
                self.results["visualizations"] = {
                    "charts": {name: str(path) for name, path in charts.items()},
                    "chart_count": len(charts)
                }
                self.logger.info(f"Generated {len(charts)} charts")

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­
            duration = time.time() - start_time
            self.logger.info(f"\nâ±ï¸  Total processing time: {duration:.2f}s")
            self.logger.info(f"ğŸ“ˆ Processing speed: {collection_result['stats']['total_reviews'] / duration:.2f} reviews/s")

            self.logger.info("\nâœ… Analysis Complete!")
            self.logger.info("=" * 60)

            return self.results

        except Exception as e:
            self.logger.error(f"Analysis failed: {str(e)}")
            raise ReviewAnalysisException(f"Pipeline execution failed: {str(e)}")

    def _load_data(
        self,
        data_path: str,
        product_id: Optional[str],
        limit: Optional[int]
    ):
        """ë°ì´í„° ë¡œë“œ"""
        loader = JSONReviewLoader(data_path)
        df = loader.load(product_id=product_id, limit=limit)

        self.logger.info(
            f"Loaded {len(df)} reviews",
            product_id=product_id or "all"
        )

        return df

    def _preprocess_data(self, df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        df = self.preprocessor.process(df)

        self.logger.info(
            f"Preprocessing complete",
            final_count=len(df)
        )

        return df

    def _collect_data(self, df):
        """ë°ì´í„° ìˆ˜ì§‘ ë° ê¸°ë³¸ í†µê³„"""
        result = self.data_agent.execute(df)

        self.logger.info(
            "Data collection complete",
            avg_rating=round(result['stats']['avg_rating'], 2),
            negative_count=len(result['negative_reviews'])
        )

        return result

    def _analyze_sentiment(self, collection_result):
        """ê°ì„± ë¶„ì„"""
        result = self.sentiment_agent.execute(collection_result)

        self.logger.info(
            "Sentiment analysis complete",
            positive=result['sentiment_distribution'].get('positive', 0),
            negative=result['sentiment_distribution'].get('negative', 0)
        )

        return result

    def _extract_insights(self, collection_result):
        """ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ (Phase 2 - ê¸ì •/ë¶€ì • ëª¨ë‘)"""
        result = self.insight_agent.execute(collection_result)

        pain_points_count = len(result.get('pain_points', []))
        strengths_count = len(result.get('strengths', []))
        self.logger.info(
            "Insight extraction complete",
            pain_points=pain_points_count,
            strengths=strengths_count,
            aspects=len(result.get('product_aspects', {}))
        )

        return result

    def _plan_actions(self, pain_points, stats):
        """ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (Phase 2)"""
        input_data = {
            "pain_points": pain_points,
            "stats": stats
        }

        result = self.action_planning_agent.execute(input_data)

        self.logger.info(
            "Action planning complete",
            quick_wins=len(result.get('quick_wins', [])),
            medium_term=len(result.get('medium_term_actions', [])),
            long_term=len(result.get('long_term_actions', []))
        )

        return result

    def _generate_report(self, product_id, stats, insights, action_plan):
        """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Phase 2)"""
        input_data = {
            "product_id": product_id,
            "stats": stats,
            "insights": insights,
            "action_plan": action_plan
        }

        result = self.report_agent.execute(input_data)

        self.logger.info(
            "Report generation complete",
            findings=len(result.get('key_findings', [])),
            actions=len(result.get('immediate_actions', []))
        )

        return result

    def get_summary(self) -> str:
        """
        ë¶„ì„ ê²°ê³¼ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„± (Phase 2 í¬í•¨)

        Returns:
            ìš”ì•½ í…ìŠ¤íŠ¸
        """
        if not self.results:
            return "No analysis results available."

        stats = self.results.get('basic_stats', {})
        sentiment = self.results.get('sentiment_analysis', {})
        sentiment_dist = sentiment.get('sentiment_distribution', {})

        summary_lines = [
            "ğŸ“Š ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ìš”ì•½",
            "",
            "ê¸°ë³¸ í†µê³„:",
            f"- ì´ ë¦¬ë·° ìˆ˜: {stats.get('total_reviews', 0):,}ê°œ",
            f"- í‰ê·  í‰ì : {stats.get('avg_rating', 0):.2f}/5.0",
            f"- í‰ê·  ë¦¬ë·° ê¸¸ì´: {stats.get('avg_review_length', 0):.0f}ì",
            "",
            "ê°ì„± ë¶„ì„:",
            f"- ê¸ì • ë¦¬ë·°: {sentiment_dist.get('positive', 0):,}ê°œ ({sentiment_dist.get('positive', 0) / stats.get('total_reviews', 1) * 100:.1f}%)",
            f"- ë¶€ì • ë¦¬ë·°: {sentiment_dist.get('negative', 0):,}ê°œ ({sentiment_dist.get('negative', 0) / stats.get('total_reviews', 1) * 100:.1f}%)",
            f"- ì¤‘ë¦½ ë¦¬ë·°: {sentiment_dist.get('neutral', 0):,}ê°œ",
        ]

        # Phase 2 ê²°ê³¼ ì¶”ê°€
        if "insights" in self.results:
            insights = self.results["insights"]
            pain_points = insights.get("pain_points", [])

            summary_lines.extend([
                "",
                "ğŸ” ì£¼ìš” ì¸ì‚¬ì´íŠ¸:",
                f"- ë°œê²¬ëœ ë¬¸ì œì : {len(pain_points)}ê°œ"
            ])

            # Top 3 pain points í‘œì‹œ
            for i, pain_point in enumerate(pain_points[:3], 1):
                issue = pain_point.get("issue", "Unknown")
                severity = pain_point.get("severity", "unknown")
                summary_lines.append(f"  {i}. [{severity.upper()}] {issue}")

        if "action_plan" in self.results:
            action_plan = self.results["action_plan"]
            quick_wins = action_plan.get("quick_wins", [])
            total_actions = (
                len(quick_wins) +
                len(action_plan.get("medium_term_actions", [])) +
                len(action_plan.get("long_term_actions", []))
            )

            summary_lines.extend([
                "",
                "ğŸ“‹ ì‹¤í–‰ ê³„íš:",
                f"- ì´ ê¶Œì¥ ì•¡ì…˜: {total_actions}ê°œ",
                f"- Quick Win: {len(quick_wins)}ê°œ"
            ])

        if "final_report" in self.results:
            report = self.results["final_report"]
            summary_lines.extend([
                "",
                "ğŸ“„ ìµœì¢… ë¦¬í¬íŠ¸:",
                f"- í•µì‹¬ ë°œê²¬: {len(report.get('key_findings', []))}ê°œ",
                f"- ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”: {len(report.get('immediate_actions', []))}ê°œ"
            ])

        summary_lines.extend([
            "",
            "ë¶„ì„ ì •ë³´:",
            f"- ì œí’ˆ ID: {self.results['metadata'].get('product_id', 'N/A')}",
            f"- ë¶„ì„ ì‹œê°: {self.results['metadata'].get('timestamp', 'N/A')}",
            f"- ì‹œìŠ¤í…œ ë²„ì „: {self.results['metadata'].get('version', 'N/A')}"
        ])

        return "\n".join(summary_lines)

    def save_results(self, output_path: str):
        """
        ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

        Args:
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        import json

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        self.logger.info(f"Results saved to {output_path}")

    def _generate_visualizations(self, df, sentiment_result):
        """
        ì‹œê°í™” ìƒì„± (Phase 3)

        Args:
            df: ë¦¬ë·° DataFrame
            sentiment_result: ê°ì„± ë¶„ì„ ê²°ê³¼

        Returns:
            ìƒì„±ëœ ì°¨íŠ¸ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            sentiment_dist = sentiment_result.get('sentiment_distribution', {})
            absa_results = sentiment_result.get('absa', None)

            charts = self.visualization_service.generate_all_charts(
                df=df,
                sentiment_distribution=sentiment_dist,
                absa_results=absa_results
            )

            return charts

        except Exception as e:
            self.logger.warning(f"Visualization failed: {str(e)}")
            return None
