"""
ì‹¤í—˜ 2: í˜¼í•© ê°ì • (Multi-Aspect Sentiment) ë¶„ì„ - MAMS ë°ì´í„°ì…‹ ì‚¬ìš©

ëª©ì : í•œ ë¦¬ë·° ë‚´ì—ì„œ ë‹¤ë¥¸ ê°ì •ì„ ê°€ì§„ ì—¬ëŸ¬ aspectë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë¶„ë¦¬í•˜ëŠ”ì§€ ì¸¡ì •
ë°ì´í„°: MAMS (Multi-Aspect Multi-Sentiment) - EMNLP-IJCNLP 2019

MAMS íŠ¹ì§•: ëª¨ë“  ë¬¸ì¥ì´ 2ê°œ ì´ìƒì˜ ë‹¤ë¥¸ ê°ì • aspect í¬í•¨
â†’ ë³„ì  ê¸°ë°˜ì€ ì´ë¡ ì ìœ¼ë¡œ ~33% í•œê³„ (ëª¨ë“  aspectì— ë™ì¼ ê°ì • ë¶€ì—¬)
"""
import sys
import time
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Any, Tuple
import random

# src í´ë”ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

import pandas as pd
from agents.sentiment_agent import SentimentAnalysisAgent
from services.llm_service import create_llm_service
from utils.logger import get_logger
import yaml

logger = get_logger(__name__)


def load_llm_service():
    """LLM ì„œë¹„ìŠ¤ ë¡œë“œ"""
    config_path = project_root / 'src' / 'config' / 'llm_config.yaml'
    with open(config_path, 'r', encoding='utf-8') as f:
        llm_config = yaml.safe_load(f)
    return create_llm_service(llm_config)


def load_mams_dataset(split: str = 'test', max_samples: int = None) -> List[Dict]:
    """
    MAMS ë°ì´í„°ì…‹ ë¡œë“œ (XML íŒŒì‹±)
    
    Args:
        split: 'train', 'val', 'test'
        max_samples: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´)
    
    Returns:
        List of {text, aspects: [{term, polarity}]}
    """
    mams_path = project_root / 'datasets' / 'mams' / f'{split}.xml'
    
    if not mams_path.exists():
        raise FileNotFoundError(f"MAMS ë°ì´í„°ì…‹ ì—†ìŒ: {mams_path}")
    
    tree = ET.parse(mams_path)
    root = tree.getroot()
    
    samples = []
    for sentence in root.findall('.//sentence'):
        text_elem = sentence.find('text')
        if text_elem is None:
            continue
        
        text = text_elem.text
        aspects = []
        
        for aspect_term in sentence.findall('.//aspectTerm'):
            term = aspect_term.get('term')
            polarity = aspect_term.get('polarity')
            
            # MAMS polarity: positive, negative, neutral
            if term and polarity:
                aspects.append({
                    'term': term,
                    'polarity': polarity
                })
        
        if len(aspects) >= 2:  # MAMSëŠ” 2ê°œ ì´ìƒ aspect ë³´ì¥
            samples.append({
                'text': text,
                'aspects': aspects
            })
    
    # ìƒ˜í”Œ ìˆ˜ ì œí•œ
    if max_samples and len(samples) > max_samples:
        samples = random.sample(samples, max_samples)
    
    return samples


def has_mixed_sentiment(sample: Dict) -> bool:
    """í˜¼í•© ê°ì • (ë‹¤ë¥¸ polarity) ì—¬ë¶€ í™•ì¸"""
    polarities = set(a['polarity'] for a in sample['aspects'])
    return len(polarities) >= 2


def fuzzy_match_aspect(target_term: str, llm_result: Dict[str, str], nlp=None) -> str:
    """
    Fuzzy matching + spaCy ì˜ë¯¸ ìœ ì‚¬ë„ë¡œ LLM ê²°ê³¼ì—ì„œ aspect ì°¾ê¸°
    
    Args:
        target_term: ì°¾ê³ ì í•˜ëŠ” ì›ë³¸ aspect term
        llm_result: LLM ì‘ë‹µ {aspect: sentiment}
        nlp: spaCy ëª¨ë¸ (Noneì´ë©´ ë¡œë“œ)
    
    Returns:
        ë§¤ì¹­ëœ sentiment ë˜ëŠ” 'not_found'
    """
    target_lower = target_term.lower().strip()
    
    # 1. ì •í™•í•œ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    for key, value in llm_result.items():
        if key.lower().strip() == target_lower:
            return value
    
    # 2. ê´€ì‚¬ ì œê±° í›„ ë§¤ì¹­ (the, a, an)
    target_no_article = target_lower
    for article in ['the ', 'a ', 'an ']:
        target_no_article = target_no_article.replace(article, '')
    
    for key, value in llm_result.items():
        key_no_article = key.lower().strip()
        for article in ['the ', 'a ', 'an ']:
            key_no_article = key_no_article.replace(article, '')
        if key_no_article == target_no_article:
            return value
    
    # 3. ë¶€ë¶„ ì¼ì¹˜ (targetì´ keyì— í¬í•¨ë˜ê±°ë‚˜ keyê°€ targetì— í¬í•¨)
    for key, value in llm_result.items():
        key_lower = key.lower().strip()
        if target_lower in key_lower or key_lower in target_lower:
            return value
    
    # 4. ë‹¨ì–´ ë‹¨ìœ„ ë¶€ë¶„ ì¼ì¹˜ (í•µì‹¬ ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë§¤ì¹­)
    target_words = set(target_lower.split())
    for key, value in llm_result.items():
        key_words = set(key.lower().strip().split())
        if target_words & key_words:
            return value
    
    # 5. spaCy ì˜ë¯¸ ìœ ì‚¬ë„ (ì„ê³„ê°’ 0.6 ì´ìƒì´ë©´ ë§¤ì¹­)
    if nlp is not None:
        target_doc = nlp(target_lower)
        best_match = None
        best_score = 0.0
        
        for key, value in llm_result.items():
            key_doc = nlp(key.lower().strip())
            if target_doc.has_vector and key_doc.has_vector:
                similarity = target_doc.similarity(key_doc)
                if similarity > best_score:
                    best_score = similarity
                    best_match = value
        
        # ìœ ì‚¬ë„ 0.6 ì´ìƒì´ë©´ ë§¤ì¹­
        if best_score >= 0.6:
            return best_match
    
    return 'not_found'


# spaCy ëª¨ë¸ ê¸€ë¡œë²Œ ë¡œë“œ (í•œ ë²ˆë§Œ)
_nlp_model = None

def get_nlp_model():
    """spaCy ëª¨ë¸ ì‹±ê¸€í†¤ ë¡œë“œ"""
    global _nlp_model
    if _nlp_model is None:
        try:
            import spacy
            _nlp_model = spacy.load('en_core_web_md')
            logger.info("spaCy model loaded: en_core_web_md")
        except Exception as e:
            logger.warning(f"Failed to load spaCy model: {e}")
            _nlp_model = False  # ë¡œë“œ ì‹¤íŒ¨ í‘œì‹œ
    return _nlp_model if _nlp_model else None


def evaluate_rating_based(samples: List[Dict]) -> Dict:
    """
    ë³„ì  ê¸°ë°˜ í‰ê°€ (ëª¨ë“  aspectì— ë™ì¼ ê°ì • ë¶€ì—¬)
    
    ê°€ì •: í˜¼í•© ê°ì • ë¦¬ë·°ì—ì„œ ë³„ì  ê¸°ë°˜ì€ ê°€ì¥ ë¹ˆë²ˆí•œ ê°ì •ìœ¼ë¡œ ì˜ˆì¸¡
    """
    total_aspects = 0
    correct_aspects = 0
    
    for sample in samples:
        # ê°€ì¥ ë¹ˆë²ˆí•œ polarityë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš© (ë³„ì  ê¸°ë°˜ ê°€ì •)
        polarities = [a['polarity'] for a in sample['aspects']]
        # Baseline: í†µê³„ì ìœ¼ë¡œ ê°€ì¥ ë§ì€ 'neutral'ë¡œ ëª¨ë‘ ì˜ˆì¸¡ (Majority Class)
        # MAMS ë°ì´í„°ì…‹ì€ ì¤‘ë¦½ ê°ì •ì´ ë§¤ìš° ë§ìŒ
        majority_polarity = 'neutral'
        
        for aspect in sample['aspects']:
            total_aspects += 1
            if majority_polarity == aspect['polarity']:
                correct_aspects += 1
    
    return {
        'method': 'rating_based',
        'accuracy': correct_aspects / total_aspects if total_aspects > 0 else 0,
        'correct': correct_aspects,
        'total': total_aspects
    }


def evaluate_llm_based(samples: List[Dict], agent: SentimentAnalysisAgent, 
                       max_samples: int = 100) -> Dict:
    """
    LLM ê¸°ë°˜ í‰ê°€ (aspectë³„ ê°ì • ë¶„ë¦¬)
    """
    if not agent.llm_service:
        return {'method': 'llm_based', 'accuracy': 0, 'correct': 0, 'total': 0}
    
    # spaCy ëª¨ë¸ ë¡œë“œ (ì˜ë¯¸ ìœ ì‚¬ë„ìš©)
    nlp = get_nlp_model()
    
    # ìƒ˜í”Œ ìˆ˜ ì œí•œ (LLM í˜¸ì¶œ ë¹„ìš©)
    eval_samples = samples[:max_samples] if len(samples) > max_samples else samples
    
    total_aspects = 0
    correct_aspects = 0
    details = []
    
    for idx, sample in enumerate(eval_samples):
        text = sample['text']
        true_aspects = sample['aspects']
        
        # LLMìœ¼ë¡œ aspect ê°ì • ë¶„ì„
        try:
            # ì‹¤ì œ aspect term ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            aspect_terms = [a['term'] for a in true_aspects]
            sentiment_result = agent._llm_aspect_sentiment(text, aspect_terms)
            
            # ìš”ì²­ ê°„ ë”œë ˆì´ (Ollama ê³¼ë¶€í•˜ ë°©ì§€)
            time.sleep(2.0)
        except Exception as e:
            logger.warning(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            sentiment_result = {}
            time.sleep(5.0)
        
        case_result = {
            'text': text[:80] + '...' if len(text) > 80 else text,
            'aspect_results': []
        }
        
        for aspect in true_aspects:
            term = aspect['term']
            true_polarity = aspect['polarity']
            total_aspects += 1
            
            # LLM ê²°ê³¼ì—ì„œ í•´ë‹¹ aspect ì°¾ê¸° (Fuzzy Matching + spaCy ì˜ë¯¸ ìœ ì‚¬ë„)
            predicted = fuzzy_match_aspect(term, sentiment_result, nlp)
            
            # ì •ê·œí™”
            if predicted in ['not_mentioned', 'unknown']:
                predicted = 'not_found'
            
            is_correct = predicted == true_polarity
            if is_correct:
                correct_aspects += 1
            
            case_result['aspect_results'].append({
                'term': term,
                'true': true_polarity,
                'predicted': predicted,
                'correct': is_correct
            })
        
        details.append(case_result)
        
        # ì§„í–‰ë¥  ì¶œë ¥
        if (idx + 1) % 20 == 0:
            print(f"   ì§„í–‰: {idx + 1}/{len(eval_samples)}")
    
    return {
        'method': 'llm_based',
        'accuracy': correct_aspects / total_aspects if total_aspects > 0 else 0,
        'correct': correct_aspects,
        'total': total_aspects,
        'details': details
    }


def run_mams_experiment(max_llm_samples: int = 100):
    """MAMS í˜¼í•© ê°ì • ë¶„ì„ ì‹¤í—˜ ì‹¤í–‰"""
    print("=" * 70)
    print("ğŸ”€ ì‹¤í—˜ 2: í˜¼í•© ê°ì • ë¶„ì„ (MAMS Dataset)")
    print("=" * 70)
    print("ğŸ“š ë°ì´í„°: MAMS (EMNLP-IJCNLP 2019)")
    print("ğŸ“– íŠ¹ì§•: ëª¨ë“  ë¬¸ì¥ì´ 2+ ë‹¤ë¥¸ ê°ì • aspect í¬í•¨")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    print("\nğŸ“‚ MAMS ë°ì´í„°ì…‹ ë¡œë“œ...")
    try:
        samples = load_mams_dataset('test')
        mixed_count = sum(1 for s in samples if has_mixed_sentiment(s))
        total_aspects = sum(len(s['aspects']) for s in samples)
        
        print(f"   âœ… ë¬¸ì¥ ìˆ˜: {len(samples)}")
        print(f"   âœ… ì´ aspect ìˆ˜: {total_aspects}")
        print(f"   âœ… í˜¼í•© ê°ì • ë¬¸ì¥: {mixed_count} ({100*mixed_count/len(samples):.1f}%)")
    except FileNotFoundError as e:
        print(f"   âŒ {e}")
        return None
    
    # LLM ì„œë¹„ìŠ¤ ë¡œë“œ
    print("\nğŸ“¡ LLM ì„œë¹„ìŠ¤ ë¡œë“œ...")
    try:
        llm_service = load_llm_service()
        print("   âœ… LLM service ready")
    except Exception as e:
        print(f"   âŒ LLM ë¡œë“œ ì‹¤íŒ¨: {e}")
        llm_service = None
    # llm_service = None # ì£¼ì„ ì œê±°
    
    config = {'log_level': 'WARNING'}
    agent = SentimentAnalysisAgent(config, llm_service)
    
    
    results = {}
    
    # ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ (Baseline ê²°ê³¼ ìœ ì§€ ëª©ì )
    output_path = project_root / 'experiments' / 'results' / 'mams_mixed_sentiment.json'
    if output_path.exists():
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                existing = json.load(f)
                if 'rating_based' in existing:
                    results['rating_based'] = existing['rating_based']
                    print("   âœ… ê¸°ì¡´ Baseline ê²°ê³¼ ë¡œë“œë¨")
        except:
            pass
    
    # ===== ë°©ë²• A: ë³„ì  ê¸°ë°˜ =====
    print("\n" + "-" * 50)
    print("ğŸ“Œ ë°©ë²• A: ë³„ì  ê¸°ë°˜ (ëª¨ë“  aspectì— ë™ì¼ ê°ì •)")
    
    # ì´ë¯¸ ë¡œë“œëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if 'rating_based' not in results:
        result_rating = evaluate_rating_based(samples)
        results['rating_based'] = result_rating
    else:
        result_rating = results['rating_based']
    
    print(f"   Accuracy: {result_rating['accuracy']:.2%}")
    print(f"   ì •ë‹µ: {result_rating['correct']}/{result_rating['total']}")
    
    # ===== ë°©ë²• B: LLM ê¸°ë°˜ =====
    print("\n" + "-" * 50)
    print(f"ğŸ“Œ ë°©ë²• B: LLM ê¸°ë°˜ (aspectë³„ ê°ì • ë¶„ë¦¬, {max_llm_samples}ê°œ ìƒ˜í”Œ)")
    
    if llm_service:
        result_llm = evaluate_llm_based(samples, agent, max_samples=max_llm_samples)
        results['llm_based'] = result_llm
        
        print(f"\n   Accuracy: {result_llm['accuracy']:.2%}")
        print(f"   ì •ë‹µ: {result_llm['correct']}/{result_llm['total']}")
        
        # ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
        if 'details' in result_llm and result_llm['details']:
            print("\n   ğŸ“‹ ìƒ˜í”Œ ê²°ê³¼:")
            for detail in result_llm['details'][:3]:
                print(f"\n   \"{detail['text']}\"")
                for ar in detail['aspect_results']:
                    status = "âœ…" if ar['correct'] else "âŒ"
                    print(f"      {status} {ar['term']}: {ar['predicted']} (ì •ë‹µ: {ar['true']})")
    else:
        print("   âš ï¸ LLM ì„œë¹„ìŠ¤ ì—†ìŒ")
    
    # ===== ê²°ê³¼ ìš”ì•½ =====
    print("\n" + "=" * 70)
    print("ğŸ“Š MAMS í˜¼í•© ê°ì • ë¶„ì„ ê²°ê³¼")
    print("=" * 70)
    
    print(f"\n{'ë°©ë²•':<30} {'Accuracy':<15} {'ì •ë‹µ/ì „ì²´':<15}")
    print("-" * 60)
    print(f"{'A. ë³„ì  ê¸°ë°˜':<30} {result_rating['accuracy']:.2%}{'':<10} {result_rating['correct']}/{result_rating['total']}")
    
    if 'llm_based' in results:
        r = results['llm_based']
        print(f"{'B. LLM ê¸°ë°˜':<30} {r['accuracy']:.2%}{'':<10} {r['correct']}/{r['total']}")
        
        improvement = r['accuracy'] - result_rating['accuracy']
        print(f"\nğŸ“ˆ ê°œì„ : +{improvement:.2%}")
    
    # ê²°ê³¼ ì €ì¥
    output_path = project_root / 'experiments' / 'results' / 'mams_mixed_sentiment.json'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    save_results = {
        'dataset': 'MAMS',
        'total_samples': len(samples),
        'llm_samples': max_llm_samples,
        'rating_based': {k: v for k, v in results['rating_based'].items()},
    }
    if 'llm_based' in results:
        save_results['llm_based'] = {
            k: v for k, v in results['llm_based'].items() if k != 'details'
        }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(save_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    
    return results


if __name__ == "__main__":
    run_mams_experiment(max_llm_samples=1000)  # 500ê°œ ìƒ˜í”Œë¡œ í†µê³„ì  ìœ ì˜ì„± í™•ë³´
