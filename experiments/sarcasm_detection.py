"""
ì‹¤í—˜ 3: ë°˜ì–´ë²• (Sarcasm) íƒì§€ - SARC ë°ì´í„°ì…‹ ì‚¬ìš©

ëª©ì : LLMì´ ë°˜ì–´ë²•ì„ ì–¼ë§ˆë‚˜ ì˜ ê°ì§€í•˜ëŠ”ì§€ ì¸¡ì •
ë°ì´í„°: SARC (Self-Annotated Reddit Corpus) - LREC 2018

SARC íŠ¹ì§•: 
- Reddit ëŒ“ê¸€ ê¸°ë°˜
- ì‘ì„±ìê°€ ì§ì ‘ /s íƒœê·¸ë¡œ sarcasm í‘œì‹œ
- 1M+ ëŒ“ê¸€ (balanced: 50/50)
"""
import sys
import csv
import json
import random
import time
from pathlib import Path
from typing import Dict, List, Any

# src í´ë”ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

from services.llm_service import create_llm_service
from utils.logger import get_logger
import yaml
from jinja2 import Template

logger = get_logger(__name__)


def load_llm_service():
    """LLM ì„œë¹„ìŠ¤ ë¡œë“œ"""
    config_path = project_root / 'src' / 'config' / 'llm_config.yaml'
    with open(config_path, 'r', encoding='utf-8') as f:
        llm_config = yaml.safe_load(f)
    return create_llm_service(llm_config)


def load_sarc_dataset(max_samples: int = 500) -> List[Dict]:
    """
    SARC ë°ì´í„°ì…‹ ë¡œë“œ
    
    Args:
        max_samples: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (balanced: sarcastic/non-sarcastic ë°˜ë°˜)
    
    Returns:
        List of {comment, label, parent_comment}
    """
    # train-balanced-sarcasm.csv ì‚¬ìš© (ë” ê¹¨ë—í•œ í¬ë§·)
    sarc_path = project_root / 'datasets' / 'sarc' / 'train-balanced-sarcasm.csv'
    
    if not sarc_path.exists():
        # test-balanced.csv ì‹œë„
        sarc_path = project_root / 'datasets' / 'sarc' / 'test-balanced.csv'
    
    if not sarc_path.exists():
        raise FileNotFoundError(f"SARC ë°ì´í„°ì…‹ ì—†ìŒ: {sarc_path}")
    
    samples = {'sarcastic': [], 'non_sarcastic': []}
    
    with open(sarc_path, 'r', encoding='utf-8', errors='ignore') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            comment = row.get('comment', '')
            label = row.get('label', '')
            parent = row.get('parent_comment', '')
            
            if not comment or len(comment) < 10:
                continue
            
            if len(comment) > 500:  # ë„ˆë¬´ ê¸´ ëŒ“ê¸€ ì œì™¸
                continue
            
            sample = {
                'comment': comment,
                'label': int(label) if label.isdigit() else 0,
                'parent_comment': parent
            }
            
            if sample['label'] == 1:
                samples['sarcastic'].append(sample)
            else:
                samples['non_sarcastic'].append(sample)
            
            # ì¶©ë¶„íˆ ëª¨ì•˜ìœ¼ë©´ ì¤‘ë‹¨
            if len(samples['sarcastic']) >= max_samples and len(samples['non_sarcastic']) >= max_samples:
                break
    
    # Balanced ìƒ˜í”Œë§
    n_each = max_samples // 2
    selected = []
    
    if len(samples['sarcastic']) >= n_each:
        selected.extend(random.sample(samples['sarcastic'], n_each))
    else:
        selected.extend(samples['sarcastic'])
    
    if len(samples['non_sarcastic']) >= n_each:
        selected.extend(random.sample(samples['non_sarcastic'], n_each))
    else:
        selected.extend(samples['non_sarcastic'])
    
    random.shuffle(selected)
    return selected


def evaluate_surface_sentiment(samples: List[Dict]) -> Dict:
    """
    í‘œë©´ì  ê°ì • ê¸°ë°˜ í‰ê°€ (ë°˜ì–´ë²• êµ¬ë¶„ ë¶ˆê°€)
    
    Sarcastic ëŒ“ê¸€ì€ í‘œë©´ì ìœ¼ë¡œ ê¸ì •ì ì´ì§€ë§Œ ì‹¤ì œëŠ” ë¶€ì •ì 
    â†’ í‘œë©´ ê°ì •ë§Œ ë³´ë©´ sarcasmì„ ë†“ì¹¨
    """
    # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ê°ì • ë¶„ì„
    positive_words = {'great', 'love', 'amazing', 'awesome', 'good', 'best', 'wonderful', 'excellent', 'perfect', 'nice'}
    negative_words = {'bad', 'terrible', 'awful', 'worst', 'hate', 'horrible', 'disgusting', 'poor', 'fail', 'sucks'}
    
    correct = 0
    total = len(samples)
    
    for sample in samples:
        text = sample['comment'].lower()
        
        # í‘œë©´ì  ê°ì • íŒë‹¨
        pos_count = sum(1 for w in positive_words if w in text)
        neg_count = sum(1 for w in negative_words if w in text)
        
        if pos_count > neg_count:
            predicted_sarcasm = 0  # ê¸ì • í‘œí˜„ â†’ sarcasmì´ ì•„ë‹ˆë¼ê³  ì˜ˆì¸¡
        elif neg_count > pos_count:
            predicted_sarcasm = 0  # ë¶€ì • í‘œí˜„ â†’ ì§ì ‘ì  ë¶€ì •ì´ë¯€ë¡œ sarcasm ì•„ë‹˜
        else:
            predicted_sarcasm = 0  # ì¤‘ë¦½ â†’ sarcasmì´ ì•„ë‹ˆë¼ê³  ì˜ˆì¸¡
        
        if predicted_sarcasm == sample['label']:
            correct += 1
    
    return {
        'method': 'surface_sentiment',
        'accuracy': correct / total if total > 0 else 0,
        'correct': correct,
        'total': total
    }


def evaluate_llm_based(samples: List[Dict], llm_service, max_samples: int = 500) -> Dict:
    """LLM ê¸°ë°˜ ë°˜ì–´ë²• íƒì§€"""
    if not llm_service:
        return {'method': 'llm_based', 'accuracy': 0, 'correct': 0, 'total': 0}
    
    eval_samples = samples[:max_samples]
    
    sarcasm_prompt = Template("""
ë‹¤ìŒ Reddit ëŒ“ê¸€ì´ ë¬¸ë§¥(ë¶€ëª¨ ëŒ“ê¸€)ì„ ê³ ë ¤í–ˆì„ ë•Œ ë°˜ì–´ë²•(sarcasm)ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

ë°˜ì–´ë²•ì€ í‘œë©´ì ìœ¼ë¡œëŠ” ê¸ì •ì ì´ê±°ë‚˜ ì¹­ì°¬í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, 
ì‹¤ì œ ì˜ë„ëŠ” ë¹„ê¼¼/ì¡°ë¡±/ë¹„íŒì¸ í‘œí˜„ì…ë‹ˆë‹¤. ë¶€ëª¨ ëŒ“ê¸€ì— ëŒ€í•œ ë°˜ì‘ì„ì„ ê³ ë ¤í•˜ì„¸ìš”.

ë¶€ëª¨ ëŒ“ê¸€ (Context): "{{ parent }}"
ëŒ€ìƒ ëŒ“ê¸€ (Reply): "{{ comment }}"

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”:
{"is_sarcasm": true ë˜ëŠ” false, "confidence": 0.0-1.0, "reason": "ê°„ë‹¨í•œ ì´ìœ "}
""")
    
    correct = 0
    total = 0
    sarcasm_correct = 0
    sarcasm_total = 0
    details = []
    
    for idx, sample in enumerate(eval_samples):
        try:
            prompt = sarcasm_prompt.render(
                comment=sample['comment'][:300],
                parent=sample['parent_comment'][:300]
            )
            response = llm_service.generate_json(prompt, max_tokens=10000, temperature=0.3)
            
            # ìš”ì²­ ê°„ ë”œë ˆì´ (Ollama ê³¼ë¶€í•˜ ë°©ì§€)
            time.sleep(2.0)  # 1ì´ˆ â†’ 2ì´ˆë¡œ ì¦ê°€
            
            if response and 'is_sarcasm' in response:
                predicted = 1 if response['is_sarcasm'] else 0
            else:
                predicted = 0  # í´ë°±
        except Exception as e:
            logger.warning(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            predicted = 0
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¶”ê°€ ëŒ€ê¸°
            time.sleep(5.0)
        
        actual = sample['label']
        is_correct = predicted == actual
        
        if is_correct:
            correct += 1
        
        if actual == 1:  # ì‹¤ì œ sarcasmì¸ ê²½ìš°
            sarcasm_total += 1
            if is_correct:
                sarcasm_correct += 1
        
        total += 1
        
        details.append({
            'comment': sample['comment'][:60] + '...',
            'actual': actual,
            'predicted': predicted,
            'correct': is_correct
        })
        
        # ì§„í–‰ë¥  ì¶œë ¥
        if (idx + 1) % 50 == 0:
            print(f"   ì§„í–‰: {idx + 1}/{len(eval_samples)}")
    
    return {
        'method': 'llm_based',
        'accuracy': correct / total if total > 0 else 0,
        'correct': correct,
        'total': total,
        'sarcasm_accuracy': sarcasm_correct / sarcasm_total if sarcasm_total > 0 else 0,
        'sarcasm_correct': sarcasm_correct,
        'sarcasm_total': sarcasm_total,
        'details': details
    }


def run_sarcasm_experiment(max_samples: int = 500):
    """SARC ë°˜ì–´ë²• íƒì§€ ì‹¤í—˜ ì‹¤í–‰"""
    print("=" * 70)
    print("ğŸ˜ ì‹¤í—˜ 3: ë°˜ì–´ë²• íƒì§€ (SARC Dataset)")
    print("=" * 70)
    print("ğŸ“š ë°ì´í„°: SARC (Self-Annotated Reddit Corpus)")
    print("ğŸ“– íŠ¹ì§•: Reddit ì‚¬ìš©ìê°€ /s íƒœê·¸ë¡œ ì§ì ‘ ë¼ë²¨ë§")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    print(f"\nğŸ“‚ SARC ë°ì´í„°ì…‹ ë¡œë“œ ({max_samples}ê°œ ìƒ˜í”Œ)...")
    try:
        samples = load_sarc_dataset(max_samples)
        sarcasm_count = sum(1 for s in samples if s['label'] == 1)
        
        print(f"   âœ… ë¡œë“œ ì™„ë£Œ: {len(samples)}ê°œ")
        print(f"   âœ… Sarcastic: {sarcasm_count}")
        print(f"   âœ… Non-sarcastic: {len(samples) - sarcasm_count}")
    except FileNotFoundError as e:
        print(f"   âŒ {e}")
        return None
    
    # LLM ì„œë¹„ìŠ¤ ë¡œë“œ
    print("\nğŸ“¡ LLM ì„œë¹„ìŠ¤ ë¡œë“œ...")
    try:
        llm_service = load_llm_service()
        print("   âœ… LLM service ready")
    except Exception as e:
        print(f"   âŒ LLM ë¡œë“œ ì‹¤íŒ¨: {e}")
        llm_service = None
    
    results = {}
    
    # ===== ë°©ë²• A: í‘œë©´ ê°ì • ê¸°ë°˜ =====
    print("\n" + "-" * 50)
    print("ğŸ“Œ ë°©ë²• A: í‘œë©´ ê°ì • ê¸°ë°˜ (ë°˜ì–´ë²• êµ¬ë¶„ ë¶ˆê°€)")
    
    result_surface = evaluate_surface_sentiment(samples)
    results['surface'] = result_surface
    
    print(f"   Accuracy: {result_surface['accuracy']:.2%}")
    print(f"   ì •ë‹µ: {result_surface['correct']}/{result_surface['total']}")
    
    # ===== ë°©ë²• B: LLM ê¸°ë°˜ =====
    print("\n" + "-" * 50)
    print(f"ğŸ“Œ ë°©ë²• B: LLM ê¸°ë°˜ ({max_samples}ê°œ ìƒ˜í”Œ)")
    
    if llm_service:
        result_llm = evaluate_llm_based(samples, llm_service, max_samples)
        results['llm_based'] = result_llm
        
        print(f"\n   ì „ì²´ Accuracy: {result_llm['accuracy']:.2%}")
        print(f"   Sarcasm Recall: {result_llm['sarcasm_accuracy']:.2%}")
        print(f"   ì •ë‹µ: {result_llm['correct']}/{result_llm['total']}")
        
        # ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
        if 'details' in result_llm:
            print("\n   ğŸ“‹ ìƒ˜í”Œ:")
            for detail in result_llm['details'][:3]:
                status = "âœ…" if detail['correct'] else "âŒ"
                label = "SARC" if detail['actual'] == 1 else "NORM"
                pred = "SARC" if detail['predicted'] == 1 else "NORM"
                print(f"      {status} [{label}â†’{pred}] \"{detail['comment']}\"")
    else:
        print("   âš ï¸ LLM ì„œë¹„ìŠ¤ ì—†ìŒ")
    
    # ===== ê²°ê³¼ ìš”ì•½ =====
    print("\n" + "=" * 70)
    print("ğŸ“Š SARC ë°˜ì–´ë²• íƒì§€ ê²°ê³¼")
    print("=" * 70)
    
    print(f"\n{'ë°©ë²•':<30} {'Accuracy':<15} {'Sarcasm Recall':<15}")
    print("-" * 60)
    print(f"{'A. í‘œë©´ ê°ì • ê¸°ë°˜':<30} {result_surface['accuracy']:.2%}")
    
    if 'llm_based' in results:
        r = results['llm_based']
        print(f"{'B. LLM ê¸°ë°˜':<30} {r['accuracy']:.2%}{'':<6} {r['sarcasm_accuracy']:.2%}")
        
        improvement = r['accuracy'] - result_surface['accuracy']
        print(f"\nğŸ“ˆ ê°œì„ : +{improvement:.2%}")
    
    # ê²°ê³¼ ì €ì¥
    output_path = project_root / 'experiments' / 'results' / 'sarc_sarcasm.json'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    save_results = {
        'dataset': 'SARC',
        'total_samples': len(samples),
        'surface': result_surface,
    }
    if 'llm_based' in results:
        save_results['llm_based'] = {
            k: v for k, v in results['llm_based'].items() if k != 'details'
        }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(save_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    
    return results


if __name__ == "__main__":
    run_sarcasm_experiment(max_samples=1000)  # 1000ê°œ ìƒ˜í”Œë¡œ í†µê³„ì  ìœ ì˜ì„± í™•ë³´
