"""
Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ (Phase 5)

ê°„ë‹¨í•œ ì›¹ ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‹¤í–‰:
    streamlit run scripts/web_interface.py
"""
import streamlit as st
import pandas as pd
import json
from pathlib import Path
import sys
from datetime import datetime
import time

# src í´ë”ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

from core.orchestrator import ReviewAnalysisOrchestrator
from utils.logger import get_logger

logger = get_logger(__name__)


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Amazon Review Analysis System",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # í—¤ë”
    st.markdown('<p class="main-header">ğŸ“Š Amazon Review Analysis System</p>', unsafe_allow_html=True)
    st.markdown("**Version 4.0.0** | Multi-Agent AI System for Business Insights")
    st.divider()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ
        st.subheader("1. ë°ì´í„° ì—…ë¡œë“œ")

        # ìƒ˜í”Œ ë°ì´í„° ë²„íŠ¼ ì¶”ê°€
        use_sample = st.button("ğŸ¯ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë°”ë¡œ í…ŒìŠ¤íŠ¸", use_container_width=True)

        if use_sample:
            st.session_state['use_sample'] = True

        uploaded_file = st.file_uploader(
            "Amazon ë¦¬ë·° JSON íŒŒì¼",
            type=['json'],
            help="Amazon ë¦¬ë·° ë°ì´í„° JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )

        if uploaded_file:
            st.session_state['use_sample'] = False

        # ë¶„ì„ ì˜µì…˜
        st.subheader("2. ë¶„ì„ ì˜µì…˜")

        product_id = st.text_input(
            "ì œí’ˆ ID (ASIN)",
            value="ALL",
            help="ë¶„ì„í•  ì œí’ˆì˜ ASIN ì½”ë“œ (ALL = ëª¨ë“  ë¦¬ë·° ë¶„ì„)",
            placeholder="ì˜ˆ: B000000000, B001234567, B007XYZ123..."
        )

        st.caption("ğŸ’¡ **ALL** ì…ë ¥ ì‹œ ë°ì´í„°ì…‹ì˜ ëª¨ë“  ë¦¬ë·°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤")

        limit = st.slider(
            "ë¶„ì„í•  ë¦¬ë·° ìˆ˜",
            min_value=10,
            max_value=1000,
            value=100,
            step=10,
            help="ì„¤ì •í•œ ê°œìˆ˜ë§Œí¼ LLMì´ ë¶„ì„í•©ë‹ˆë‹¤ (ë¬´ì‘ìœ„ ì„ê¸°)"
        )

        st.caption("ğŸ’¡ ì²˜ë¦¬ ì‹œê°„: 10ê°œ=30ì´ˆ, 50ê°œ=2ë¶„, 100ê°œ=3-4ë¶„, 500ê°œ=10-15ë¶„, 1000ê°œ=20-30ë¶„")
        st.caption("âœ¨ **ìë™ ë°°ì¹˜ ì²˜ë¦¬**: 100ê°œ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ë°°ì¹˜ ë¶„í• í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤")

        enable_llm = st.checkbox(
            "LLM ë¶„ì„ í™œì„±í™”",
            value=True,
            help="ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ë° ì‹¤í–‰ ê³„íš ìƒì„± (ì‹œê°„ ì†Œìš”)"
        )

        cache_enabled = st.checkbox(
            "ìºì‹± í™œì„±í™”",
            value=True,
            help="LLM ì‘ë‹µ ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ"
        )

        st.divider()

        # ì •ë³´
        st.subheader("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        st.info("""
        **Phase 1-5 ì™„ë£Œ**
        - ê°ì„± ë¶„ì„ (ABSA)
        - LLM ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        - ì‹¤í–‰ ê³„íš ìƒì„±
        - ì‹œê°í™”
        - ê²½ìŸì‚¬ ë¹„êµ
        """)

    # ë©”ì¸ ì˜ì—­
    if uploaded_file is None and not st.session_state.get('use_sample', False):
        # ì‹œì‘ í™”ë©´
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ìƒ˜í”Œ ë°ì´í„°ë¡œ ë°”ë¡œ í…ŒìŠ¤íŠ¸' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ ë¦¬ë·° ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”!")

        # ê¸°ëŠ¥ ì†Œê°œ
        col1, col2, col3 = st.columns(3)

        with col1:
            st.subheader("ğŸ“ˆ ê¸°ë³¸ ë¶„ì„")
            st.write("- í‰ì  ë¶„í¬")
            st.write("- ì‹œê°„ ì¶”ì´")
            st.write("- ê°ì„± ë¶„ë¥˜")

        with col2:
            st.subheader("ğŸ” ABSA ë¶„ì„")
            st.write("- Aspect ì¶”ì¶œ")
            st.write("- Aspectë³„ ê°ì„±")
            st.write("- ë¬¸ì œì  ë°œê²¬")

        with col3:
            st.subheader("ğŸ’¡ LLM ì¸ì‚¬ì´íŠ¸")
            st.write("- ë¬¸ì œì  ë„ì¶œ")
            st.write("- ì‹¤í–‰ ê³„íš")
            st.write("- ê²½ì˜ì§„ ë³´ê³ ì„œ")

        # ìƒ˜í”Œ ê²°ê³¼ í‘œì‹œ
        st.subheader("ğŸ“Š ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼")

        sample_data = {
            "ì´ ë¦¬ë·° ìˆ˜": 100,
            "í‰ê·  í‰ì ": 3.8,
            "ê¸ì • ë¦¬ë·°": "45%",
            "ë¶€ì • ë¦¬ë·°": "30%"
        }

        cols = st.columns(4)
        for i, (key, value) in enumerate(sample_data.items()):
            with cols[i]:
                st.metric(label=key, value=value)

        return

    # ë¶„ì„ ì‹¤í–‰
    st.subheader("ğŸš€ ë¶„ì„ ì‹¤í–‰")

    if st.button("ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        # ì§„í–‰ ìƒí™©
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            # 1. íŒŒì¼ ì €ì¥
            status_text.text("ğŸ“ íŒŒì¼ ì¤€ë¹„ ì¤‘...")
            progress_bar.progress(10)

            # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸
            if st.session_state.get('use_sample', False):
                # ì›ë³¸ CSVì—ì„œ ë¬´ì‘ìœ„ ìƒ˜í”Œë§ (ë§¤ë²ˆ ë‹¤ë¥¸ ë¦¬ë·° ì„ íƒ)
                import csv
                import json
                import random
                import hashlib

                source_file = Path("datasets/test.csv")

                # 1ë‹¨ê³„: CSV íŒŒì¼ ì „ì²´ ë¼ì¸ ìˆ˜ ì¹´ìš´íŠ¸ (ë¹ ë¥¸ ìƒ˜í”Œë§ì„ ìœ„í•´)
                with open(source_file, 'r', encoding='utf-8') as f:
                    total_lines = sum(1 for _ in f)

                # 2ë‹¨ê³„: ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§í•  ë¼ì¸ ë²ˆí˜¸ ì„ íƒ
                sample_size = min(limit, total_lines)
                sampled_lines = sorted(random.sample(range(total_lines), sample_size))

                # 3ë‹¨ê³„: ì„ íƒëœ ë¼ì¸ë§Œ ì½ì–´ì„œ JSONìœ¼ë¡œ ë³€í™˜
                sample_reviews = []
                with open(source_file, 'r', encoding='utf-8') as f:
                    csv_reader = csv.reader(f)
                    for line_num, row in enumerate(csv_reader):
                        if line_num in sampled_lines:
                            try:
                                label = row[0].strip('"')
                                title = row[1].strip('"') if len(row) > 1 else ""
                                review_text = row[2].strip('"') if len(row) > 2 else ""

                                # CSV ë¼ë²¨ì„ ë³„ì ìœ¼ë¡œ ë³€í™˜ (1=ë¶€ì •, 2=ê¸ì •)
                                overall = 1.0 if label == "1" else 5.0

                                # ê³ ìœ  ID ìƒì„±
                                review_hash = hashlib.md5(review_text.encode()).hexdigest()[:16]

                                # Amazon ë¦¬ë·° JSON í˜•ì‹
                                review_json = {
                                    "reviewerID": f"R{review_hash}",
                                    "asin": "B000000000",
                                    "reviewerName": f"Reviewer_{len(sample_reviews)+1}",
                                    "helpful": [0, 0],
                                    "reviewText": review_text,
                                    "overall": overall,
                                    "summary": title,
                                    "unixReviewTime": 1577836800,
                                    "reviewTime": "01 01, 2020"
                                }
                                sample_reviews.append(review_json)
                            except:
                                continue

                        if len(sample_reviews) >= sample_size:
                            break

                # 4ë‹¨ê³„: ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_path = Path(f"output/temp/sample_{limit}_reviews.json")
                temp_path.parent.mkdir(parents=True, exist_ok=True)

                with open(temp_path, 'w', encoding='utf-8') as f:
                    for review in sample_reviews:
                        f.write(json.dumps(review, ensure_ascii=False) + '\n')

                st.success(f"âœ… ì›ë³¸ CSVì—ì„œ {len(sample_reviews)}ê°œ ë¦¬ë·°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤! (ë§¤ë²ˆ ë‹¤ë¥¸ ë¦¬ë·°)")
            else:
                # ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©
                temp_path = Path("output/temp") / uploaded_file.name
                temp_path.parent.mkdir(parents=True, exist_ok=True)

                with open(temp_path, 'wb') as f:
                    f.write(uploaded_file.getbuffer())

            # 2. Orchestrator ì´ˆê¸°í™”
            status_text.text("âš™ï¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            progress_bar.progress(20)

            config = {
                'output_dir': 'output/web',
                'cache_enabled': cache_enabled,
                'aspect_keywords_path': 'src/config/aspect_keywords/electronics.yaml'
            }

            orchestrator = ReviewAnalysisOrchestrator(
                config=config,
                llm_config_path='src/config/llm_config.yaml'
            )

            # 3. ë¶„ì„ ì‹¤í–‰
            status_text.text("ğŸ”¬ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            progress_bar.progress(30)

            start_time = time.time()

            # product_idê°€ "ALL", "UNKNOWN" ë“±ì´ë©´ Noneìœ¼ë¡œ ë³€ê²½ (ëª¨ë“  ë¦¬ë·° ë¶„ì„)
            actual_product_id = None if product_id.upper() in ["ALL", "UNKNOWN"] else product_id

            result = orchestrator.run_analysis(
                data_path=str(temp_path),
                product_id=actual_product_id,
                limit=limit,
                enable_llm=enable_llm
            )

            execution_time = time.time() - start_time

            progress_bar.progress(100)
            status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")

            # 4. ê²°ê³¼ í‘œì‹œ
            st.success(f"ë¶„ì„ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {execution_time:.2f}ì´ˆ)")

            # ê¸°ë³¸ í†µê³„
            st.subheader("ğŸ“Š ê¸°ë³¸ í†µê³„")

            basic_stats = result['basic_stats']

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(
                    label="ì´ ë¦¬ë·° ìˆ˜",
                    value=basic_stats['total_reviews']
                )

            with col2:
                st.metric(
                    label="í‰ê·  í‰ì ",
                    value=f"{basic_stats['avg_rating']:.2f}",
                    delta=f"{basic_stats['avg_rating'] - 3.0:.2f}"
                )

            with col3:
                sentiment_dist = result['sentiment_analysis']['sentiment_distribution']
                total = sum(sentiment_dist.values())
                positive_ratio = sentiment_dist.get('positive', 0) / total * 100 if total > 0 else 0
                st.metric(
                    label="ê¸ì • ë¹„ìœ¨",
                    value=f"{positive_ratio:.1f}%"
                )

            with col4:
                negative_ratio = sentiment_dist.get('negative', 0) / total * 100 if total > 0 else 0
                st.metric(
                    label="ë¶€ì • ë¹„ìœ¨",
                    value=f"{negative_ratio:.1f}%"
                )

            # í‰ì  ë¶„í¬
            st.subheader("â­ í‰ì  ë¶„í¬")

            rating_dist = basic_stats['rating_distribution']
            rating_df = pd.DataFrame({
                'í‰ì ': list(rating_dist.keys()),
                'ë¦¬ë·° ìˆ˜': list(rating_dist.values())
            })

            st.bar_chart(rating_df.set_index('í‰ì '))

            # ê°ì„± ë¶„ì„
            st.subheader("ğŸ˜Š ê°ì„± ë¶„ì„")

            col1, col2 = st.columns(2)

            with col1:
                st.write("**ê°ì„± ë¶„í¬**")
                sentiment_df = pd.DataFrame({
                    'ê°ì„±': list(sentiment_dist.keys()),
                    'ê°œìˆ˜': list(sentiment_dist.values())
                })
                st.dataframe(sentiment_df, use_container_width=True)

            with col2:
                st.write("**Aspect ìš”ì•½ (Top 5)**")
                aspect_summary = result['sentiment_analysis'].get('aspect_summary', [])[:5]

                if aspect_summary:
                    aspect_df = pd.DataFrame(aspect_summary)
                    # ì»¬ëŸ¼ ì´ë¦„ í™•ì¸: 'mentions' (sentiment_agent.py line 216)
                    if 'mentions' in aspect_df.columns:
                        st.dataframe(aspect_df[['aspect', 'mentions', 'avg_rating', 'dominant_sentiment']], use_container_width=True)
                    else:
                        st.dataframe(aspect_df, use_container_width=True)
                else:
                    st.info("Aspect ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # LLM ì¸ì‚¬ì´íŠ¸ (í™œì„±í™”ëœ ê²½ìš°)
            if enable_llm and 'insights' in result and result['insights']:
                st.subheader("ğŸ’¡ LLM ì¸ì‚¬ì´íŠ¸")

                # íƒ­ìœ¼ë¡œ êµ¬ë¶„: ê°•ì  ë¨¼ì €, ë¬¸ì œì ì€ ë’¤ë¡œ
                tab1, tab2 = st.tabs(["âœ… ê°•ì  (Strengths)", "âŒ ë¬¸ì œì  (Pain Points)"])

                with tab1:
                    strengths = result['insights'].get('strengths', [])

                    if strengths:
                        st.write(f"**ë°œê²¬ëœ ê°•ì : {len(strengths)}ê°œ**")

                        for i, strength in enumerate(strengths[:5], 1):
                            with st.expander(f"ê°•ì  {i}: {strength.get('feature', 'N/A')}"):
                                st.write(f"**ë¹ˆë„**: {strength.get('frequency', 'N/A')}")

                                quotes = strength.get('representative_quotes', [])
                                if quotes:
                                    st.write("**ëŒ€í‘œ ì¸ìš©**:")
                                    for quote in quotes[:3]:
                                        st.success(quote)
                    else:
                        st.info("ê°•ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                with tab2:
                    pain_points = result['insights'].get('pain_points', [])

                    if pain_points:
                        st.write(f"**ë°œê²¬ëœ ë¬¸ì œì : {len(pain_points)}ê°œ**")

                        for i, pain_point in enumerate(pain_points[:5], 1):
                            with st.expander(f"ë¬¸ì œì  {i}: {pain_point.get('issue', 'N/A')}"):
                                st.write(f"**ë¹ˆë„**: {pain_point.get('frequency', 'N/A')}")
                                st.write(f"**ì‹¬ê°ë„**: {pain_point.get('severity', 'N/A')}")

                                quotes = pain_point.get('representative_quotes', [])
                                if quotes:
                                    st.write("**ëŒ€í‘œ ì¸ìš©**:")
                                    for quote in quotes[:3]:
                                        st.info(quote)
                    else:
                        st.info("ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            # ì‹¤í–‰ ê³„íš (í™œì„±í™”ëœ ê²½ìš°)
            if enable_llm and 'action_plan' in result and result['action_plan']:
                st.subheader("ğŸ¯ ì‹¤í–‰ ê³„íš")

                action_plan = result['action_plan'].get('action_plan', {})

                tab1, tab2, tab3 = st.tabs(["Quick Wins", "Medium-term", "Long-term"])

                with tab1:
                    quick_wins = action_plan.get('quick_wins', [])
                    if quick_wins:
                        for i, action in enumerate(quick_wins, 1):
                            st.markdown(f"**{i}. {action.get('action', 'N/A')}**")
                            st.write(f"- ê·¼ê±°: {action.get('rationale', 'N/A')}")
                            st.write(f"- ì˜ˆìƒ íš¨ê³¼: {action.get('expected_impact', 'N/A')}")
                            st.divider()
                    else:
                        st.info("Quick Wins ì—†ìŒ")

                with tab2:
                    medium_actions = action_plan.get('medium_term_actions', [])
                    if medium_actions:
                        for i, action in enumerate(medium_actions, 1):
                            st.markdown(f"**{i}. {action.get('action', 'N/A')}**")
                            st.write(f"- ê·¼ê±°: {action.get('rationale', 'N/A')}")
                            st.divider()
                    else:
                        st.info("Medium-term Actions ì—†ìŒ")

                with tab3:
                    long_actions = action_plan.get('long_term_actions', [])
                    if long_actions:
                        for i, action in enumerate(long_actions, 1):
                            st.markdown(f"**{i}. {action.get('action', 'N/A')}**")
                            st.write(f"- ê·¼ê±°: {action.get('rationale', 'N/A')}")
                            st.divider()
                    else:
                        st.info("Long-term Actions ì—†ìŒ")

            # ì‹œê°í™” (ìˆëŠ” ê²½ìš°)
            if 'visualizations' in result and result['visualizations']:
                st.subheader("ğŸ“ˆ ì‹œê°í™”")

                charts = result['visualizations'].get('charts', {})

                if charts:
                    col1, col2 = st.columns(2)

                    chart_items = list(charts.items())

                    for i, (name, path) in enumerate(chart_items):
                        if Path(path).exists():
                            with col1 if i % 2 == 0 else col2:
                                st.image(path, caption=name, use_container_width=True)

            # JSON ë‹¤ìš´ë¡œë“œ
            st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")

            json_str = json.dumps(result, indent=2, ensure_ascii=False, default=str)

            st.download_button(
                label="ğŸ“¥ JSON ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=json_str,
                file_name=f"analysis_result_{product_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )

        except Exception as e:
            st.error(f"âŒ ì—ëŸ¬ ë°œìƒ: {str(e)}")

            # LLM ì—ëŸ¬ì¸ ê²½ìš° ë„ì›€ë§ í‘œì‹œ
            if "LLM" in str(e) or "None response" in str(e):
                st.warning("""
                **LLM ì—ëŸ¬ í•´ê²° ë°©ë²•:**
                1. **ë¦¬ë·° ìˆ˜ ì¤„ì´ê¸°**: 10-20ê°œë¡œ ì„¤ì •
                2. **ì ì‹œ í›„ ì¬ì‹œë„**: Ollama ì„œë²„ê°€ ë°”ì  ìˆ˜ ìˆìŠµë‹ˆë‹¤
                3. **ìºì‹± í™œì„±í™”**: ì‘ë‹µ ì†ë„ í–¥ìƒ
                """)

            # ìì„¸í•œ ì—ëŸ¬ ì •ë³´ (í™•ì¥ ê°€ëŠ¥)
            with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´"):
                st.code(str(e))

            logger.error(f"Web interface error: {e}", exc_info=True)
            progress_bar.empty()
            status_text.empty()


if __name__ == '__main__':
    main()
